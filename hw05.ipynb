{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aditya Duggirala and 1509999 \n",
    "\n",
    "**TODO**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW05 Code\n",
    "\n",
    "\n",
    "You will complete the following notebook, as described in the PDF for Homework 05 (included in the download with the starter code).  You will submit:\n",
    "1. This notebook file, along with your COLLABORATORS.txt file and the two tree images (PDFs generated using `graphviz` within the code), to the Gradescope link for code.\n",
    "2. A PDF of this notebook and all of its output, once it is completed, to the Gradescope link for the PDF.\n",
    "\n",
    "\n",
    "Please report any questions to the [class Piazza page](https://piazza.com/tufts/spring2021/comp135).\n",
    "\n",
    "### Import required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn.tree\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "threeclass_y_test = np.loadtxt('data_abalone/3class_y_test.csv', skiprows=1, delimiter=',')\n",
    "threeclass_y_train = np.loadtxt('data_abalone/3class_y_train.csv', skiprows=1, delimiter=',')\n",
    "\n",
    "small_binary_x_test = np.loadtxt('data_abalone/small_binary_x_test.csv', skiprows=1, delimiter=',')\n",
    "small_binary_x_train = np.loadtxt('data_abalone/small_binary_x_train.csv', skiprows=1, delimiter=',')\n",
    "\n",
    "x_test = np.loadtxt('data_abalone/x_test.csv', skiprows=1, delimiter=',')\n",
    "x_train = np.loadtxt('data_abalone/x_train.csv', skiprows=1, delimiter=',')\n",
    "\n",
    "y_test = np.loadtxt('data_abalone/y_test.csv', skiprows=1, delimiter=',')\n",
    "y_train = np.loadtxt('data_abalone/y_train.csv', skiprows=1, delimiter=',')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees\n",
    "\n",
    "You should start by computing the two heuristic values for the toy data described in the assignment handout. You should then load the two versions of the abalone data, compute the two heuristic values on features (for the simplified data), and then build decision trees for each set of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Compute both heuristics for toy data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Compute the counting-based heuristic, and order the features by it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature A: 2/8 - Correctness: 0.250\n",
      "Feature B: 4/8 - Correctness: 0.500\n"
     ]
    }
   ],
   "source": [
    "# Toy data\n",
    "toy_data = {'A': [1, 1, 0, 0, 0, 0, 0, 0],\n",
    "            'B': [1, 1, 1, 1, 0, 0, 0, 0],\n",
    "            'label': ['o', 'o', 'x', 'x', 'x', 'x', 'x', 'x']}\n",
    "df_toy = pd.DataFrame(toy_data)\n",
    "\n",
    "# Compute counting-based heuristic for Feature A\n",
    "correctness_A = np.sum(df_toy[df_toy['A'] == 1]['label'] == 'o') / len(df_toy)\n",
    "print(f'Feature A: {np.sum(df_toy[\"A\"] == 1)}/{len(df_toy)} - Correctness: {correctness_A:.3f}')\n",
    "\n",
    "# Compute counting-based heuristic for Feature B\n",
    "correctness_B = np.sum(df_toy[df_toy['B'] == 1]['label'] == 'o') / np.sum(df_toy['B'] == 1)\n",
    "print(f'Feature B: {np.sum(df_toy[\"B\"] == 1)}/{len(df_toy)} - Correctness: {correctness_B:.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Compute the information-theoretic heuristic, and order the features by it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: 1.000\n",
      "B: 0.000\n"
     ]
    }
   ],
   "source": [
    "# Toy data\n",
    "toy_data = {'A': [1, 1, 0, 0, 0, 0, 0, 0],\n",
    "            'B': [1, 1, 1, 1, 0, 0, 0, 0],\n",
    "            'label': ['o', 'o', 'x', 'x', 'x', 'x', 'x', 'x']}\n",
    "df_toy = pd.DataFrame(toy_data)\n",
    "\n",
    "# Define feature matrix (X) and target variable (y)\n",
    "X = df_toy[['A', 'B']]\n",
    "y = df_toy['label']\n",
    "\n",
    "# Initialize a decision tree model\n",
    "model = sklearn.tree.DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the decision tree model\n",
    "model.fit(X, y)\n",
    "\n",
    "# Extract feature importances (proxy for information gain)\n",
    "feature_importances = model.feature_importances_\n",
    "\n",
    "# Create a DataFrame to store feature names and importances\n",
    "feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importances})\n",
    "\n",
    "# Order features by importance\n",
    "features_ordered_by_info_gain = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Print the sorted features with information gain\n",
    "for index, row in features_ordered_by_info_gain.iterrows():\n",
    "    print(f\"{row['Feature']}: {row['Importance']:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) Discussion of results.\n",
    "\n",
    "\n",
    "Feature A: Correctly classifies 2 out of 8 instances (o types) in the true branch. Incorrectly classifies 2 o types and 4 x types in the false branch.\n",
    "\n",
    "Feature B: Correctly classifies 3 o types and 1 x type in the true branch. Incorrectly classifies 1 o type and 3 x types in the false branch.\n",
    "\n",
    "Information-Theoretic Gain:\n",
    "\n",
    "Feature A: Has importance 1.0, suggesting it is perfectly informative for predicting the target variable.\n",
    "\n",
    "Feature B: Has importance 0.0, indicating it does not contribute to the prediction according to the decision tree.\n",
    "\n",
    "Counting-Based Correctness:\n",
    "\n",
    "Feature B has a higher correctness rate (0.500) compared to Feature A (0.250). This suggests that, based on the provided data, Feature B performs better in terms of correctness.\n",
    "\n",
    "\n",
    "The decision tree assigns maximum importance to Feature A (1.0) and no importance to Feature B (0.0). This implies that the decision tree sees Feature A as highly informative and Feature B as not contributing to the prediction.\n",
    "\n",
    "The discrepancy in results between the two heuristics highlights that different heuristics can lead to different feature selections.\n",
    "Counting-based correctness focuses on the percentage of correct classifications, while information-theoretic gain aims to reduce uncertainty about the target variable.\n",
    "\n",
    "In practice, the choice of heuristic can impact the structure of the decision tree and its predictive performance. The optimal heuristic depends on the characteristics of the dataset and the goals of the modeling task. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Compute both heuristics for simplified abalone data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Compute the counting-based heuristic, and order the features by it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simplified Abalone Data:\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 1. 1. 1.]\n",
      " ...\n",
      " [0. 1. 1. 1.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "\n",
      "Features Ordered by Counting-Based Correctness:\n",
      "[0. 0. 1. ... 1. 0. 0.]: 0.729\n",
      "[0. 1. 1. ... 1. 0. 0.]: 0.713\n",
      "[0. 1. 1. ... 1. 0. 0.]: 0.702\n",
      "[0. 0. 0. ... 0. 0. 0.]: 0.587\n"
     ]
    }
   ],
   "source": [
    "# Display the simplified abalone data\n",
    "print(\"Simplified Abalone Data:\")\n",
    "print(small_binary_x_train)\n",
    "\n",
    "# Compute counting-based correctness for each feature\n",
    "counting_correctness_values = []\n",
    "for i, feature in enumerate(small_binary_x_train.T):  # Transpose to iterate over columns\n",
    "    correctness = counting_correctness(small_binary_x_train[:, i], threeclass_y_train)\n",
    "    counting_correctness_values.append((feature, correctness))\n",
    "\n",
    "# Order features by counting-based correctness\n",
    "ordered_features_counting = sorted(counting_correctness_values, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print the ordered features with counting-based correctness\n",
    "print(\"\\nFeatures Ordered by Counting-Based Correctness:\")\n",
    "for feature, correctness in ordered_features_counting:\n",
    "    print(f\"{feature}: {correctness:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Compute the information-theoretic heuristic, and order the features by it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Features Ordered by Feature Importance:\n",
      "height_mm: 0.883\n",
      "diam_mm: 0.079\n",
      "is_male: 0.034\n",
      "length_mm: 0.005\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import graphviz\n",
    "\n",
    "# Define a function to fit a decision tree and get feature importances\n",
    "def get_feature_importances(X, y):\n",
    "    model = DecisionTreeClassifier(random_state=42)\n",
    "    model.fit(X, y)\n",
    "    importances = model.feature_importances_\n",
    "    return importances\n",
    "\n",
    "# Convert NumPy array to DataFrame\n",
    "df_small_binary_x_train = pd.DataFrame(small_binary_x_train, columns=['is_male', 'length_mm', 'diam_mm', 'height_mm'])\n",
    "\n",
    "# Compute feature importances for each feature\n",
    "feature_importances = get_feature_importances(df_small_binary_x_train, threeclass_y_train)\n",
    "\n",
    "# Order features by importance\n",
    "ordered_features_importance = sorted(zip(df_small_binary_x_train.columns, feature_importances), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print the ordered features with feature importance\n",
    "print(\"\\nFeatures Ordered by Feature Importance:\")\n",
    "for feature, importance in ordered_features_importance:\n",
    "    print(f\"{feature}: {importance:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Generate decision trees for full- and restricted-feature data\n",
    "\n",
    "#### (a) Print accuracy values and generate tree images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for Simplified_Abalone - Test Data: 0.722\n",
      "Accuracy for Simplified_Abalone - Training Data: 0.733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy for Full_Abalone - Test Data: 0.204\n",
      "Accuracy for Full_Abalone - Training Data: 1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(process:21456): GLib-GIO-WARNING **: 08:06:27.039: Unexpectedly, UWP app `Clipchamp.Clipchamp_2.8.3.0_neutral__yxz26nhyzhsrt' (AUMId `Clipchamp.Clipchamp_yxz26nhyzhsrt!App') supports 41 extensions but has no verbs\n",
      "\n",
      "(process:21456): GLib-GIO-WARNING **: 08:06:27.140: Unexpectedly, UWP app `Microsoft.ScreenSketch_11.2310.54.0_x64__8wekyb3d8bbwe' (AUMId `Microsoft.ScreenSketch_8wekyb3d8bbwe!App') supports 29 extensions but has no verbs\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.metrics import accuracy_score\n",
    "import graphviz\n",
    "\n",
    "# Function to train Decision Tree, print accuracy, and export the tree as a PDF image\n",
    "def train_decision_tree_and_export(dataset_name, X_train, y_train, X_test, y_test):\n",
    "    # Train Decision Tree with entropy criterion\n",
    "    dt = DecisionTreeClassifier(criterion='entropy', random_state=42)\n",
    "    dt.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on test data\n",
    "    predictions_test = dt.predict(X_test)\n",
    "    predictions_train = dt.predict(X_train)\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy_test = accuracy_score(y_test, predictions_test)\n",
    "    accuracy_train = accuracy_score(y_train, predictions_train)\n",
    "\n",
    "    # Print accuracy values\n",
    "    print(f\"\\nAccuracy for {dataset_name} - Test Data: {accuracy_test:.3f}\")\n",
    "    print(f\"Accuracy for {dataset_name} - Training Data: {accuracy_train:.3f}\")\n",
    "\n",
    "    # Export the tree as a PDF image with a specified figure size\n",
    "    dot_data = export_graphviz(dt, out_file=None, feature_names=None, class_names=None, filled=True, rounded=True,\n",
    "                               special_characters=True)\n",
    "    \n",
    "    # Set a custom figure size to avoid out-of-range dimensions\n",
    "    graph = graphviz.Source(dot_data, format='pdf')\n",
    "    graph.render(f\"{dataset_name}_tree\", format='pdf', view=True)\n",
    "\n",
    "# Train and export for simplified abalone data\n",
    "train_decision_tree_and_export(\"Simplified_Abalone\", small_binary_x_train, threeclass_y_train, small_binary_x_test, threeclass_y_test)\n",
    "\n",
    "# Train and export for full abalone data\n",
    "train_decision_tree_and_export(\"Full_Abalone\", x_train, y_train, x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Discuss the results seen for the two trees\n",
    "\n",
    "Simplified Abalone Tree:\n",
    "Accuracy:\n",
    "Test Data: 72.2%\n",
    "Training Data: 73.3%\n",
    "\n",
    "\n",
    "The tree has decent accuracy on both the training and test sets, suggesting a reasonable generalization to unseen data.\n",
    "The similarity between training and test accuracies indicates that the model is not overfitting.\n",
    "\n",
    "Full Abalone Tree:\n",
    "Accuracy:\n",
    "Test Data: 20.4%\n",
    "Training Data: 100%\n",
    "\n",
    "\n",
    "The model performs well on the training set, achieving 100% accuracy. However, this could be a sign of overfitting.\n",
    "\n",
    "The significant drop in accuracy on the test set (20.4%) indicates the model doesn't perform well on new, unseen data.\n",
    "\n",
    "\n",
    "The simplified abalone tree outperforms the full abalone tree in terms of accuracy on both training and test data.\n",
    "The full abalone tree seems to overfit the training data, resulting in poor performance on the test set.\n",
    "\n",
    "\n",
    "The full abalone tree is likely more complex, capturing noise in the training data rather than the underlying patterns.\n",
    "Potential Issues with Full Abalone Tree:\n",
    "\n",
    "The perfect accuracy on the training set suggests overfitting, where the model memorizes the training data.\n",
    "The low accuracy on the test set indicates that the model might not generalize well to new data.\n",
    "\n",
    "\n",
    "Simplified Abalone Tree:\n",
    "\n",
    "Offers better generalization to new data.\n",
    "More robust and less likely to be influenced by noise.\n",
    "\n",
    "Full Abalone Tree:\n",
    "\n",
    "Demonstrates overfitting to the training data.\n",
    "Less suitable for making predictions on new, unseen instances.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
